{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import torch\n",
    "import torchvision # torch package for vision related things\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "import torchvision.datasets as datasets  # Standard datasets\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn  # All neural network modules\n",
    "from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.\n",
    "from tqdm import tqdm  # For nice progress bar!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self,in_channels=1,num_classes=10):\n",
    "        super(LeNet,self).__init__()\n",
    "        self.pool=nn.AvgPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "        self.conv1=nn.Conv2d(in_channels=in_channels,out_channels=6,kernel_size=(5,5),stride=(1,1))\n",
    "        self.conv2=nn.Conv2d(in_channels=6,out_channels=16,kernel_size=(5,5),stride=(1,1))\n",
    "        self.conv3=nn.Conv2d(in_channels=16,out_channels=120,kernel_size=(5,5),stride=(1,1))\n",
    "        self.fc1=nn.Linear(120,84)\n",
    "        self.fc2=nn.Linear(84,num_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.conv1(x))\n",
    "        x=(self.pool(x))\n",
    "        x=F.relu(self.conv2(x))\n",
    "        x=(self.pool(x))\n",
    "        x=F.relu(self.conv3(x))\n",
    "        x=x.reshape(x.shape[0],-1)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LeNet(in_channels=1,num_classes=10).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamters\n",
    "\n",
    "input_size=784\n",
    "num_classes=10\n",
    "learning_rate=0.001\n",
    "batch_size=64\n",
    "num_epochs=5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Loss and Optimizer\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "train_dataset=datasets.MNIST(root='datasets/',train=True,transform=transforms.ToTensor(),download=True)\n",
    "train_loader=DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "test_dataset=datasets.MNIST(root='datasets/',train=False,transform=transforms.ToTensor(),download=True)\n",
    "test_loader=DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader,model):\n",
    "    num_correct=0\n",
    "    num_samples=0\n",
    "    model.eval()  # to turn off batch normalisation and dropout layers\n",
    "\n",
    "    with torch.no_grad():  # to turn off backprobagation\n",
    "        for x, y in loader:\n",
    "            x=x.to(device=device)\n",
    "            x=F.pad(input=x,pad=(2,2,2,2)).to(device=device) # make the image 32x32 dimension instead of 28x28\n",
    "\n",
    "            y=torch.tensor(y).to(device=device)\n",
    "\n",
    "            scores=model(x)\n",
    "            _, predictions=scores.max(1)  #max return a tuple (max element, max element index)\n",
    "            num_correct+= (predictions==y).sum()\n",
    "            num_samples+= predictions.size(0)\n",
    "        #print('accuracy=',((float(num_correct)/num_samples)*100) )\n",
    "\n",
    "    model.train()   # to return model back to training mode\n",
    "    return (float(num_correct)/num_samples)*100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:10<00:00, 89.78it/s]\n",
      "100%|██████████| 938/938 [00:10<00:00, 89.17it/s]\n",
      "100%|██████████| 938/938 [00:10<00:00, 88.63it/s]\n",
      "100%|██████████| 938/938 [00:10<00:00, 87.50it/s]\n",
      "100%|██████████| 938/938 [00:11<00:00, 84.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train Network\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data,targets) in enumerate(tqdm(train_loader)):\n",
    "\n",
    "        #getting the data\n",
    "        data=F.pad(input=data,pad=(2,2,2,2)).to(device=device)\n",
    "        targets=targets.to(device=device)\n",
    "        # data is the batch of data, targets is the target label of each sample in the batch\n",
    "\n",
    "\n",
    "        #forward\n",
    "        scores=model(data)\n",
    "        loss=criterion(scores,targets)\n",
    "        \n",
    "        torch.set_grad_enabled(True)  # Context-manager \n",
    "\n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        #gradient descent\n",
    "        optimizer.step()\n",
    "    #print('epoch_num=',epoch,'   Train accuracy=',check_accuracy(model=model,loader=train_dataset))\n",
    "    #print('=======================================================')\n",
    "\n",
    "        \n",
    "\n",
    "#check_accuracy(model,test_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14503/3490710108.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y=torch.tensor(y).to(device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy= 98.7\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy=',check_accuracy(loader=test_loader,model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn((64,1,28,28)).to(device=device)\n",
    "#x=F.interpolate(x,size=(32,32))\n",
    "x=F.pad(input=x,pad=(2,2,2,2)).to(device=device)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0996, -0.0322, -0.0199, -0.0383, -0.0553, -0.0302, -0.0988, -0.0511,\n",
       "         -0.1087, -0.0296],\n",
       "        [ 0.0970, -0.0357, -0.0128, -0.0413, -0.0552, -0.0238, -0.1010, -0.0581,\n",
       "         -0.1044, -0.0287],\n",
       "        [ 0.1020, -0.0373, -0.0208, -0.0473, -0.0551, -0.0219, -0.0977, -0.0525,\n",
       "         -0.1073, -0.0317],\n",
       "        [ 0.0983, -0.0361, -0.0185, -0.0401, -0.0521, -0.0263, -0.0989, -0.0529,\n",
       "         -0.1072, -0.0299],\n",
       "        [ 0.1013, -0.0345, -0.0171, -0.0445, -0.0489, -0.0292, -0.0960, -0.0561,\n",
       "         -0.1061, -0.0343],\n",
       "        [ 0.1006, -0.0373, -0.0192, -0.0422, -0.0514, -0.0251, -0.0947, -0.0532,\n",
       "         -0.1077, -0.0352],\n",
       "        [ 0.1010, -0.0342, -0.0184, -0.0425, -0.0552, -0.0249, -0.0976, -0.0556,\n",
       "         -0.1049, -0.0334],\n",
       "        [ 0.1001, -0.0387, -0.0170, -0.0418, -0.0551, -0.0250, -0.0977, -0.0540,\n",
       "         -0.1061, -0.0328],\n",
       "        [ 0.1010, -0.0341, -0.0152, -0.0459, -0.0520, -0.0260, -0.0960, -0.0551,\n",
       "         -0.1039, -0.0338],\n",
       "        [ 0.1000, -0.0326, -0.0176, -0.0427, -0.0526, -0.0274, -0.0982, -0.0531,\n",
       "         -0.1082, -0.0311],\n",
       "        [ 0.0988, -0.0361, -0.0239, -0.0443, -0.0521, -0.0233, -0.0984, -0.0541,\n",
       "         -0.1088, -0.0328],\n",
       "        [ 0.0994, -0.0328, -0.0151, -0.0439, -0.0490, -0.0205, -0.0962, -0.0541,\n",
       "         -0.1060, -0.0339],\n",
       "        [ 0.1015, -0.0347, -0.0173, -0.0424, -0.0556, -0.0244, -0.0994, -0.0538,\n",
       "         -0.1052, -0.0319],\n",
       "        [ 0.0963, -0.0365, -0.0153, -0.0428, -0.0492, -0.0248, -0.0978, -0.0544,\n",
       "         -0.1075, -0.0315],\n",
       "        [ 0.0958, -0.0325, -0.0194, -0.0402, -0.0558, -0.0270, -0.0991, -0.0538,\n",
       "         -0.1099, -0.0347],\n",
       "        [ 0.1026, -0.0363, -0.0232, -0.0425, -0.0539, -0.0267, -0.0997, -0.0522,\n",
       "         -0.1068, -0.0301],\n",
       "        [ 0.1014, -0.0380, -0.0168, -0.0478, -0.0495, -0.0257, -0.0987, -0.0547,\n",
       "         -0.1073, -0.0307],\n",
       "        [ 0.1018, -0.0342, -0.0220, -0.0392, -0.0495, -0.0249, -0.0957, -0.0505,\n",
       "         -0.1061, -0.0320],\n",
       "        [ 0.0973, -0.0364, -0.0201, -0.0384, -0.0557, -0.0307, -0.0983, -0.0559,\n",
       "         -0.1086, -0.0343],\n",
       "        [ 0.1004, -0.0318, -0.0168, -0.0443, -0.0511, -0.0245, -0.0964, -0.0554,\n",
       "         -0.1045, -0.0334],\n",
       "        [ 0.0983, -0.0371, -0.0218, -0.0411, -0.0555, -0.0227, -0.0968, -0.0529,\n",
       "         -0.1087, -0.0340],\n",
       "        [ 0.0974, -0.0411, -0.0174, -0.0429, -0.0541, -0.0278, -0.0967, -0.0614,\n",
       "         -0.1051, -0.0352],\n",
       "        [ 0.1025, -0.0384, -0.0196, -0.0412, -0.0555, -0.0303, -0.1018, -0.0544,\n",
       "         -0.1027, -0.0316],\n",
       "        [ 0.1005, -0.0362, -0.0242, -0.0404, -0.0539, -0.0251, -0.1015, -0.0501,\n",
       "         -0.1083, -0.0330],\n",
       "        [ 0.0986, -0.0337, -0.0224, -0.0417, -0.0539, -0.0267, -0.1025, -0.0509,\n",
       "         -0.1073, -0.0308],\n",
       "        [ 0.0982, -0.0372, -0.0192, -0.0398, -0.0530, -0.0257, -0.0983, -0.0529,\n",
       "         -0.1081, -0.0351],\n",
       "        [ 0.1024, -0.0352, -0.0171, -0.0458, -0.0506, -0.0238, -0.0943, -0.0539,\n",
       "         -0.1090, -0.0308],\n",
       "        [ 0.0940, -0.0354, -0.0206, -0.0420, -0.0551, -0.0289, -0.0944, -0.0522,\n",
       "         -0.1115, -0.0373],\n",
       "        [ 0.0981, -0.0345, -0.0173, -0.0428, -0.0577, -0.0244, -0.1011, -0.0541,\n",
       "         -0.1048, -0.0317],\n",
       "        [ 0.0999, -0.0383, -0.0181, -0.0425, -0.0555, -0.0262, -0.0997, -0.0515,\n",
       "         -0.1039, -0.0312],\n",
       "        [ 0.1010, -0.0325, -0.0223, -0.0422, -0.0546, -0.0285, -0.1023, -0.0471,\n",
       "         -0.1046, -0.0314],\n",
       "        [ 0.1024, -0.0350, -0.0168, -0.0433, -0.0515, -0.0216, -0.0982, -0.0525,\n",
       "         -0.1018, -0.0318],\n",
       "        [ 0.1026, -0.0320, -0.0205, -0.0441, -0.0522, -0.0243, -0.0957, -0.0496,\n",
       "         -0.1066, -0.0290],\n",
       "        [ 0.0969, -0.0371, -0.0200, -0.0402, -0.0568, -0.0254, -0.1005, -0.0537,\n",
       "         -0.1106, -0.0304],\n",
       "        [ 0.1036, -0.0351, -0.0220, -0.0414, -0.0535, -0.0268, -0.0956, -0.0516,\n",
       "         -0.1046, -0.0310],\n",
       "        [ 0.0951, -0.0320, -0.0172, -0.0440, -0.0535, -0.0223, -0.0976, -0.0545,\n",
       "         -0.1091, -0.0321],\n",
       "        [ 0.1003, -0.0324, -0.0158, -0.0419, -0.0498, -0.0277, -0.0955, -0.0532,\n",
       "         -0.1092, -0.0313],\n",
       "        [ 0.0989, -0.0345, -0.0223, -0.0401, -0.0532, -0.0271, -0.1045, -0.0552,\n",
       "         -0.1047, -0.0327],\n",
       "        [ 0.0987, -0.0299, -0.0147, -0.0442, -0.0495, -0.0195, -0.0969, -0.0539,\n",
       "         -0.1019, -0.0327],\n",
       "        [ 0.1030, -0.0325, -0.0178, -0.0418, -0.0551, -0.0252, -0.0972, -0.0521,\n",
       "         -0.1025, -0.0312],\n",
       "        [ 0.0971, -0.0336, -0.0127, -0.0442, -0.0498, -0.0238, -0.0984, -0.0555,\n",
       "         -0.1058, -0.0342],\n",
       "        [ 0.0971, -0.0350, -0.0222, -0.0406, -0.0532, -0.0245, -0.0958, -0.0506,\n",
       "         -0.1115, -0.0319],\n",
       "        [ 0.0999, -0.0351, -0.0183, -0.0418, -0.0491, -0.0277, -0.0981, -0.0511,\n",
       "         -0.1109, -0.0307],\n",
       "        [ 0.1044, -0.0338, -0.0164, -0.0476, -0.0521, -0.0219, -0.0970, -0.0522,\n",
       "         -0.1032, -0.0299],\n",
       "        [ 0.0989, -0.0334, -0.0153, -0.0438, -0.0513, -0.0207, -0.0967, -0.0546,\n",
       "         -0.1056, -0.0340],\n",
       "        [ 0.0950, -0.0316, -0.0186, -0.0405, -0.0527, -0.0282, -0.0979, -0.0531,\n",
       "         -0.1119, -0.0349],\n",
       "        [ 0.1013, -0.0353, -0.0167, -0.0441, -0.0487, -0.0243, -0.0948, -0.0522,\n",
       "         -0.1033, -0.0338],\n",
       "        [ 0.0938, -0.0306, -0.0151, -0.0409, -0.0536, -0.0232, -0.0989, -0.0539,\n",
       "         -0.1093, -0.0331],\n",
       "        [ 0.0987, -0.0371, -0.0207, -0.0405, -0.0536, -0.0260, -0.1008, -0.0532,\n",
       "         -0.1108, -0.0300],\n",
       "        [ 0.0992, -0.0356, -0.0212, -0.0354, -0.0534, -0.0258, -0.0998, -0.0571,\n",
       "         -0.1070, -0.0341],\n",
       "        [ 0.0989, -0.0381, -0.0177, -0.0434, -0.0512, -0.0260, -0.0984, -0.0526,\n",
       "         -0.1102, -0.0300],\n",
       "        [ 0.1013, -0.0347, -0.0187, -0.0439, -0.0540, -0.0267, -0.0988, -0.0551,\n",
       "         -0.1096, -0.0305],\n",
       "        [ 0.1016, -0.0334, -0.0199, -0.0410, -0.0491, -0.0244, -0.0948, -0.0520,\n",
       "         -0.1082, -0.0328],\n",
       "        [ 0.1014, -0.0347, -0.0194, -0.0413, -0.0519, -0.0305, -0.1002, -0.0569,\n",
       "         -0.1036, -0.0301],\n",
       "        [ 0.1001, -0.0349, -0.0177, -0.0384, -0.0532, -0.0215, -0.0964, -0.0534,\n",
       "         -0.1093, -0.0341],\n",
       "        [ 0.1032, -0.0332, -0.0164, -0.0438, -0.0503, -0.0250, -0.0954, -0.0515,\n",
       "         -0.1032, -0.0324],\n",
       "        [ 0.1002, -0.0314, -0.0167, -0.0457, -0.0534, -0.0210, -0.1016, -0.0510,\n",
       "         -0.1018, -0.0278],\n",
       "        [ 0.1005, -0.0384, -0.0228, -0.0448, -0.0591, -0.0281, -0.1028, -0.0530,\n",
       "         -0.1069, -0.0331],\n",
       "        [ 0.0984, -0.0320, -0.0133, -0.0406, -0.0517, -0.0257, -0.0941, -0.0528,\n",
       "         -0.1061, -0.0346],\n",
       "        [ 0.0989, -0.0369, -0.0142, -0.0427, -0.0538, -0.0246, -0.0958, -0.0543,\n",
       "         -0.1088, -0.0313],\n",
       "        [ 0.0971, -0.0361, -0.0181, -0.0426, -0.0529, -0.0212, -0.0960, -0.0530,\n",
       "         -0.1085, -0.0344],\n",
       "        [ 0.1004, -0.0376, -0.0204, -0.0414, -0.0563, -0.0233, -0.0997, -0.0529,\n",
       "         -0.1076, -0.0318],\n",
       "        [ 0.0957, -0.0351, -0.0169, -0.0442, -0.0528, -0.0251, -0.0964, -0.0552,\n",
       "         -0.1123, -0.0321],\n",
       "        [ 0.1008, -0.0306, -0.0167, -0.0413, -0.0551, -0.0240, -0.0978, -0.0506,\n",
       "         -0.1058, -0.0302]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def test_lenet():\n",
    "    x = torch.randn(64, 1, 32, 32)\n",
    "    model = LeNet()\n",
    "    return model(x)\n",
    "\n",
    "test_lenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85532dc71f3ddefdcfdbd0be1b525c1c0affee72012a798b080bb8224659b1af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-09-15T11:43:10.274255Z","iopub.status.busy":"2022-09-15T11:43:10.273722Z","iopub.status.idle":"2022-09-15T11:43:12.426143Z","shell.execute_reply":"2022-09-15T11:43:12.425010Z","shell.execute_reply.started":"2022-09-15T11:43:10.274184Z"},"trusted":true},"outputs":[],"source":["\n","# Imports\n","import torch\n","import torchvision # torch package for vision related things\n","import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n","import torchvision.datasets as datasets  # Standard datasets\n","import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n","import torchvision.transforms as transforms\n","\n","from torch import optim  # For optimizers like SGD, Adam, etc.\n","from torch import nn  # All neural network modules\n","from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.\n","from tqdm import tqdm  # For nice progress bar!\n","\n","torch.cuda.empty_cache()\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T11:43:12.429407Z","iopub.status.busy":"2022-09-15T11:43:12.428743Z","iopub.status.idle":"2022-09-15T11:43:12.504102Z","shell.execute_reply":"2022-09-15T11:43:12.503103Z","shell.execute_reply.started":"2022-09-15T11:43:12.429353Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T11:43:20.779715Z","iopub.status.busy":"2022-09-15T11:43:20.778800Z","iopub.status.idle":"2022-09-15T11:43:20.787479Z","shell.execute_reply":"2022-09-15T11:43:20.786246Z","shell.execute_reply.started":"2022-09-15T11:43:20.779660Z"},"trusted":true},"outputs":[],"source":["VGG_types = {\n","    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n","    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n","    \"VGG16\": [\n","        64,\n","        64,\n","        \"M\",\n","        128,\n","        128,\n","        \"M\",\n","        256,\n","        256,\n","        256,\n","        \"M\",\n","        512,\n","        512,\n","        512,\n","        \"M\",\n","        512,\n","        512,\n","        512,\n","        \"M\",\n","    ],\n","    \"VGG19\": [\n","        64,\n","        64,\n","        \"M\",\n","        128,\n","        128,\n","        \"M\",\n","        256,\n","        256,\n","        256,\n","        256,\n","        \"M\",\n","        512,\n","        512,\n","        512,\n","        512,\n","        \"M\",\n","        512,\n","        512,\n","        512,\n","        512,\n","        \"M\",\n","    ],\n","}"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T11:43:32.652536Z","iopub.status.busy":"2022-09-15T11:43:32.651925Z","iopub.status.idle":"2022-09-15T11:43:32.663204Z","shell.execute_reply":"2022-09-15T11:43:32.662231Z","shell.execute_reply.started":"2022-09-15T11:43:32.652500Z"},"trusted":true},"outputs":[],"source":["\n","#takes: channel x 224 x 224   image\n","class VGG(nn.Module):\n","    def __init__(self,architecture,in_channels=3,num_classes=10):\n","        super(VGG,self).__init__()\n","        self.in_channels=in_channels\n","        self.conv_filters=self.create_conv_layers(architecture)\n","        self.fc=nn.Sequential(\n","\n","            nn.Linear(7*7*512,4096),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(4096,4096),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(4096,num_classes),\n","        )\n","\n","    def forward(self,x):\n","        x=self.conv_filters(x)\n","        x= x.reshape(x.shape[0],-1)\n","        x=self.fc(x)\n","        return x\n","    def create_conv_layers(self,architecture):\n","        layers=[]\n","        in_channels=self.in_channels\n","        for x in architecture:\n","            \n","            if type(x) == int:\n","                layers+=[\n","                    nn.Conv2d(in_channels=in_channels,out_channels=x,kernel_size=(3,3),stride=(1,1),padding=(1,1)),\n","                    nn.BatchNorm2d(x),\n","                    nn.ReLU()\n","                ]\n","                in_channels=x\n","\n","            elif x == 'M':\n","                layers+=[nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))]\n","        return nn.Sequential(*layers)\n","        "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T11:43:48.341033Z","iopub.status.busy":"2022-09-15T11:43:48.340661Z","iopub.status.idle":"2022-09-15T11:43:52.707668Z","shell.execute_reply":"2022-09-15T11:43:52.706684Z","shell.execute_reply.started":"2022-09-15T11:43:48.340998Z"},"trusted":true},"outputs":[],"source":["model=VGG(architecture=VGG_types[\"VGG11\"],in_channels=1,num_classes=10).to(device=device)\n","#model=VGG_net(in_channels=1,num_classes=10).to(device=device)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T11:45:22.918984Z","iopub.status.busy":"2022-09-15T11:45:22.918601Z","iopub.status.idle":"2022-09-15T11:45:22.924095Z","shell.execute_reply":"2022-09-15T11:45:22.923031Z","shell.execute_reply.started":"2022-09-15T11:45:22.918937Z"},"trusted":true},"outputs":[],"source":["# Hyperparamters\n","\n","num_classes=10\n","learning_rate=0.001\n","batch_size=32\n","num_epochs=2\n","\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T11:45:25.323912Z","iopub.status.busy":"2022-09-15T11:45:25.322609Z","iopub.status.idle":"2022-09-15T11:45:25.329956Z","shell.execute_reply":"2022-09-15T11:45:25.328808Z","shell.execute_reply.started":"2022-09-15T11:45:25.323859Z"},"trusted":true},"outputs":[],"source":["\n","#Loss and Optimizer\n","\n","criterion=nn.CrossEntropyLoss()\n","optimizer=optim.Adam(model.parameters(),lr=learning_rate)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T11:45:26.039483Z","iopub.status.busy":"2022-09-15T11:45:26.038858Z","iopub.status.idle":"2022-09-15T11:45:26.044700Z","shell.execute_reply":"2022-09-15T11:45:26.043571Z","shell.execute_reply.started":"2022-09-15T11:45:26.039445Z"},"trusted":true},"outputs":[],"source":["my_transforms=transforms.Compose([\n","    #transforms.ToPILImage(),\n","    transforms.Resize((224,224)),\n","    transforms.ToTensor(),\n","])\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T11:45:26.757478Z","iopub.status.busy":"2022-09-15T11:45:26.756781Z","iopub.status.idle":"2022-09-15T11:45:26.839518Z","shell.execute_reply":"2022-09-15T11:45:26.838531Z","shell.execute_reply.started":"2022-09-15T11:45:26.757441Z"},"trusted":true},"outputs":[],"source":["# Loading dataset\n","train_dataset=datasets.MNIST(root='datasets/',train=True,transform=my_transforms,download=True)\n","train_loader=DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n","\n","test_dataset=datasets.MNIST(root='datasets/',train=False,transform=my_transforms,download=True)\n","test_loader=DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True)\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T11:45:34.703079Z","iopub.status.busy":"2022-09-15T11:45:34.702479Z","iopub.status.idle":"2022-09-15T11:55:26.823854Z","shell.execute_reply":"2022-09-15T11:55:26.822848Z","shell.execute_reply.started":"2022-09-15T11:45:34.703036Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1875/1875 [04:59<00:00,  6.27it/s]\n","100%|██████████| 1875/1875 [04:53<00:00,  6.40it/s]\n"]}],"source":["# Train Network\n","\n","\n","\n","for epoch in range(num_epochs):\n","    for batch_idx, (data,targets) in enumerate(tqdm(train_loader)):\n","\n","        #getting the data\n","        data=data.to(device=device)\n","        targets=targets.to(device=device)\n","        # data is the batch of data, targets is the target label of each sample in the batch\n","\n","\n","        #forward\n","        scores=model(data)\n","        loss=criterion(scores,targets)\n","        \n","        torch.set_grad_enabled(True)  # Context-manager \n","\n","        #backward\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        #gradient descent\n","        optimizer.step()\n","    #print('epoch_num=',epoch,'   Train accuracy=',check_accuracy(model=model,loader=train_dataset))\n","    #print('=======================================================')\n","\n","        \n","\n","#check_accuracy(model,test_dataset)\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T11:56:30.950887Z","iopub.status.busy":"2022-09-15T11:56:30.949853Z","iopub.status.idle":"2022-09-15T11:56:30.957782Z","shell.execute_reply":"2022-09-15T11:56:30.956691Z","shell.execute_reply.started":"2022-09-15T11:56:30.950841Z"},"trusted":true},"outputs":[],"source":["def check_accuracy(loader,model):\n","    num_correct=0\n","    num_samples=0\n","    model.eval()  # to turn off batch normalisation and dropout layers\n","\n","    with torch.no_grad():  # to turn off backprobagation\n","        for x, y in tqdm(loader):\n","            x=x.to(device=device)\n","            #x=F.pad(input=x,pad=(2,2,2,2)).to(device=device) # make the image 32x32 dimension instead of 28x28\n","\n","            y=torch.tensor(y).to(device=device)\n","\n","            scores=model(x)\n","            _, predictions=scores.max(1)  #max return a tuple (max element, max element index)\n","            num_correct+= (predictions==y).sum()\n","            num_samples+= predictions.size(0)\n","        #print('accuracy=',((float(num_correct)/num_samples)*100) )\n","\n","    model.train()   # to return model back to training mode\n","    return (float(num_correct)/num_samples)*100\n","    \n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T11:56:41.920832Z","iopub.status.busy":"2022-09-15T11:56:41.920206Z","iopub.status.idle":"2022-09-15T11:56:54.743828Z","shell.execute_reply":"2022-09-15T11:56:54.742821Z","shell.execute_reply.started":"2022-09-15T11:56:41.920796Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/313 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  # This is added back by InteractiveShellApp.init_path()\n","100%|██████████| 313/313 [00:12<00:00, 24.46it/s]"]},{"name":"stdout","output_type":"stream","text":["test accuracy= 97.54\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["print('test accuracy=',check_accuracy(loader=test_loader,model=model))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":4}

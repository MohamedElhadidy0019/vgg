{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n# Imports\nimport torch\nimport torchvision # torch package for vision related things\nimport torch.nn.functional as F  # Parameterless functions, like (some) activation functions\nimport torchvision.datasets as datasets  # Standard datasets\nimport torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\nimport torchvision.transforms as transforms\n\nfrom torch import optim  # For optimizers like SGD, Adam, etc.\nfrom torch import nn  # All neural network modules\nfrom torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.\nfrom tqdm import tqdm  # For nice progress bar!\n\ntorch.cuda.empty_cache()\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-15T11:43:10.273722Z","iopub.execute_input":"2022-09-15T11:43:10.274255Z","iopub.status.idle":"2022-09-15T11:43:12.426143Z","shell.execute_reply.started":"2022-09-15T11:43:10.274184Z","shell.execute_reply":"2022-09-15T11:43:12.425010Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-09-15T11:43:12.428743Z","iopub.execute_input":"2022-09-15T11:43:12.429407Z","iopub.status.idle":"2022-09-15T11:43:12.504102Z","shell.execute_reply.started":"2022-09-15T11:43:12.429353Z","shell.execute_reply":"2022-09-15T11:43:12.503103Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"VGG_types = {\n    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n    \"VGG16\": [\n        64,\n        64,\n        \"M\",\n        128,\n        128,\n        \"M\",\n        256,\n        256,\n        256,\n        \"M\",\n        512,\n        512,\n        512,\n        \"M\",\n        512,\n        512,\n        512,\n        \"M\",\n    ],\n    \"VGG19\": [\n        64,\n        64,\n        \"M\",\n        128,\n        128,\n        \"M\",\n        256,\n        256,\n        256,\n        256,\n        \"M\",\n        512,\n        512,\n        512,\n        512,\n        \"M\",\n        512,\n        512,\n        512,\n        512,\n        \"M\",\n    ],\n}","metadata":{"execution":{"iopub.status.busy":"2022-09-15T11:43:20.778800Z","iopub.execute_input":"2022-09-15T11:43:20.779715Z","iopub.status.idle":"2022-09-15T11:43:20.787479Z","shell.execute_reply.started":"2022-09-15T11:43:20.779660Z","shell.execute_reply":"2022-09-15T11:43:20.786246Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\n#takes: channel x 224 x 224   image\nclass VGG(nn.Module):\n    def __init__(self,architecture,in_channels=3,num_classes=10):\n        super(VGG,self).__init__()\n        self.in_channels=in_channels\n        self.conv_filters=self.create_conv_layers(architecture)\n        self.fc=nn.Sequential(\n\n            nn.Linear(7*7*512,4096),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(4096,4096),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(4096,num_classes),\n        )\n\n    def forward(self,x):\n        x=self.conv_filters(x)\n        x= x.reshape(x.shape[0],-1)\n        x=self.fc(x)\n        return x\n    def create_conv_layers(self,architecture):\n        layers=[]\n        in_channels=self.in_channels\n        for x in architecture:\n            \n            if type(x) == int:\n                layers+=[\n                    nn.Conv2d(in_channels=in_channels,out_channels=x,kernel_size=(3,3),stride=(1,1),padding=(1,1)),\n                    nn.BatchNorm2d(x),\n                    nn.ReLU()\n                ]\n                in_channels=x\n\n            elif x == 'M':\n                layers+=[nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))]\n        return nn.Sequential(*layers)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-09-15T11:43:32.651925Z","iopub.execute_input":"2022-09-15T11:43:32.652536Z","iopub.status.idle":"2022-09-15T11:43:32.663204Z","shell.execute_reply.started":"2022-09-15T11:43:32.652500Z","shell.execute_reply":"2022-09-15T11:43:32.662231Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model=VGG(architecture=VGG_types[\"VGG11\"],in_channels=1,num_classes=10).to(device=device)\n#model=VGG_net(in_channels=1,num_classes=10).to(device=device)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-15T11:43:48.340661Z","iopub.execute_input":"2022-09-15T11:43:48.341033Z","iopub.status.idle":"2022-09-15T11:43:52.707668Z","shell.execute_reply.started":"2022-09-15T11:43:48.340998Z","shell.execute_reply":"2022-09-15T11:43:52.706684Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Hyperparamters\n\nnum_classes=10\nlearning_rate=0.001\nbatch_size=32\nnum_epochs=2\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-09-15T11:45:22.918601Z","iopub.execute_input":"2022-09-15T11:45:22.918984Z","iopub.status.idle":"2022-09-15T11:45:22.924095Z","shell.execute_reply.started":"2022-09-15T11:45:22.918937Z","shell.execute_reply":"2022-09-15T11:45:22.923031Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\n#Loss and Optimizer\n\ncriterion=nn.CrossEntropyLoss()\noptimizer=optim.Adam(model.parameters(),lr=learning_rate)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-15T11:45:25.322609Z","iopub.execute_input":"2022-09-15T11:45:25.323912Z","iopub.status.idle":"2022-09-15T11:45:25.329956Z","shell.execute_reply.started":"2022-09-15T11:45:25.323859Z","shell.execute_reply":"2022-09-15T11:45:25.328808Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"my_transforms=transforms.Compose([\n    #transforms.ToPILImage(),\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n])\n","metadata":{"execution":{"iopub.status.busy":"2022-09-15T11:45:26.038858Z","iopub.execute_input":"2022-09-15T11:45:26.039483Z","iopub.status.idle":"2022-09-15T11:45:26.044700Z","shell.execute_reply.started":"2022-09-15T11:45:26.039445Z","shell.execute_reply":"2022-09-15T11:45:26.043571Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Loading dataset\ntrain_dataset=datasets.MNIST(root='datasets/',train=True,transform=my_transforms,download=True)\ntrain_loader=DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n\ntest_dataset=datasets.MNIST(root='datasets/',train=False,transform=my_transforms,download=True)\ntest_loader=DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-09-15T11:45:26.756781Z","iopub.execute_input":"2022-09-15T11:45:26.757478Z","iopub.status.idle":"2022-09-15T11:45:26.839518Z","shell.execute_reply.started":"2022-09-15T11:45:26.757441Z","shell.execute_reply":"2022-09-15T11:45:26.838531Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Train Network\n\n\n\nfor epoch in range(num_epochs):\n    for batch_idx, (data,targets) in enumerate(tqdm(train_loader)):\n\n        #getting the data\n        data=data.to(device=device)\n        targets=targets.to(device=device)\n        # data is the batch of data, targets is the target label of each sample in the batch\n\n\n        #forward\n        scores=model(data)\n        loss=criterion(scores,targets)\n        \n        torch.set_grad_enabled(True)  # Context-manager \n\n        #backward\n        optimizer.zero_grad()\n        loss.backward()\n\n        #gradient descent\n        optimizer.step()\n    #print('epoch_num=',epoch,'   Train accuracy=',check_accuracy(model=model,loader=train_dataset))\n    #print('=======================================================')\n\n        \n\n#check_accuracy(model,test_dataset)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-09-15T11:45:34.702479Z","iopub.execute_input":"2022-09-15T11:45:34.703079Z","iopub.status.idle":"2022-09-15T11:55:26.823854Z","shell.execute_reply.started":"2022-09-15T11:45:34.703036Z","shell.execute_reply":"2022-09-15T11:55:26.822848Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|██████████| 1875/1875 [04:59<00:00,  6.27it/s]\n100%|██████████| 1875/1875 [04:53<00:00,  6.40it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def check_accuracy(loader,model):\n    num_correct=0\n    num_samples=0\n    model.eval()  # to turn off batch normalisation and dropout layers\n\n    with torch.no_grad():  # to turn off backprobagation\n        for x, y in tqdm(loader):\n            x=x.to(device=device)\n            #x=F.pad(input=x,pad=(2,2,2,2)).to(device=device) # make the image 32x32 dimension instead of 28x28\n\n            y=torch.tensor(y).to(device=device)\n\n            scores=model(x)\n            _, predictions=scores.max(1)  #max return a tuple (max element, max element index)\n            num_correct+= (predictions==y).sum()\n            num_samples+= predictions.size(0)\n        #print('accuracy=',((float(num_correct)/num_samples)*100) )\n\n    model.train()   # to return model back to training mode\n    return (float(num_correct)/num_samples)*100\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-09-15T11:56:30.949853Z","iopub.execute_input":"2022-09-15T11:56:30.950887Z","iopub.status.idle":"2022-09-15T11:56:30.957782Z","shell.execute_reply.started":"2022-09-15T11:56:30.950841Z","shell.execute_reply":"2022-09-15T11:56:30.956691Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print('test accuracy=',check_accuracy(loader=test_loader,model=model))","metadata":{"execution":{"iopub.status.busy":"2022-09-15T11:56:41.920206Z","iopub.execute_input":"2022-09-15T11:56:41.920832Z","iopub.status.idle":"2022-09-15T11:56:54.743828Z","shell.execute_reply.started":"2022-09-15T11:56:41.920796Z","shell.execute_reply":"2022-09-15T11:56:54.742821Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"  0%|          | 0/313 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  # This is added back by InteractiveShellApp.init_path()\n100%|██████████| 313/313 [00:12<00:00, 24.46it/s]","output_type":"stream"},{"name":"stdout","text":"test accuracy= 97.54\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}